{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55675b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(condition, lst):\n",
    "    try:\n",
    "        if condition < 1:\n",
    "            print(\"condition < 1\")\n",
    "        else:\n",
    "            x = 0\n",
    "            while x in range(0, 3):\n",
    "                if lst[x] == \"\":\n",
    "                    print(\"I am here 1\")\n",
    "                    x = x + 1\n",
    "                else:\n",
    "                    print(\"I am here 2\")\n",
    "                    x = x + 1\n",
    "            else:\n",
    "                print(\"All good\")\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"\", \"a\", \"b\"]\n",
    "function(1, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7387777",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [[(1, 2), (1, 4)], [(7, 5), (5, 4)]]\n",
    "d = [(1, 1), (7, 5)], [(2, 4), (5, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f99cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for z, _val1 in enumerate(c):\n",
    "    x = ()\n",
    "    for y, _val2 in enumerate(_val1):\n",
    "        x += (c[z][1], )\n",
    "    a.append(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_1 = pd.DataFrame(data=[{\n",
    "    'Player': 'O. Fuglsang'\n",
    "}, {\n",
    "    'Player': 'J. Jensen-Abbew'\n",
    "}, {\n",
    "    'Player': 'M. Enggård'\n",
    "}, {\n",
    "    'Player': 'J. Liburd'\n",
    "}])\n",
    "df_2 = pd.DataFrame(data=[{\n",
    "    'Player': 'R. Mudražija',\n",
    "    'Team': 'a1',\n",
    "    'Age': 'a2',\n",
    "    'Value': 'a3'\n",
    "}, {\n",
    "    'Player': 'J. Gomez',\n",
    "    'Team': 'b1',\n",
    "    'Age': 'b2',\n",
    "    'Value': 'b3'\n",
    "}, {\n",
    "    'Player': 'T. Mølgaard',\n",
    "    'Team': 'c1',\n",
    "    'Age': 'c2',\n",
    "    'Value': 'c3'\n",
    "}, {\n",
    "    'Player': 'J. Liburd',\n",
    "    'Team': 'd1',\n",
    "    'Age': 'd2',\n",
    "    'Value': 'd3'\n",
    "}])\n",
    "result_inner_without_regex = df_1.merge(df_2)  # by default it takes inner join\n",
    "\n",
    "\n",
    "def replace_name(name):\n",
    "    return re.sub('\\w+\\.', '', name)\n",
    "\n",
    "\n",
    "df_1['Player'] = df_1['Player'].apply(replace_name)\n",
    "df_2['Player'] = df_2['Player'].apply(replace_name)\n",
    "result_with_regex_left = df_1.merge(\n",
    "    df_2, how='left')  # player as a key because only in these table\n",
    "result_with_regex_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parent:\n",
    "\n",
    "    def __init__(self, lst):\n",
    "        self.lst = lst\n",
    "\n",
    "    def return_even(self):\n",
    "        return [i for i in self.lst if i % 2 == 0]\n",
    "\n",
    "\n",
    "class Child(Parent):\n",
    "\n",
    "    def __init__(self, lst):\n",
    "        Parent.__init__(self, lst)\n",
    "\n",
    "    def return_odd(self):\n",
    "        return [i for i in self.lst if i % 2 != 0]\n",
    "\n",
    "\n",
    "class GrandChild(Child):\n",
    "\n",
    "    def __init__(self, lst):\n",
    "        Child.__init__(self, lst)\n",
    "\n",
    "    def return_reverse(self):\n",
    "        return self.lst[::-1]\n",
    "\n",
    "\n",
    "a = '16,5,4,3,211'\n",
    "a_int_lst = [int(i) for i in a.split(',')]\n",
    "# prnt = Parent(a_int_lst)\n",
    "# prnt.return_even()\n",
    "# chld = Child(a_int_lst)\n",
    "# print(chld.return_even())\n",
    "# print(chld.return_odd())\n",
    "gchld = GrandChild(a_int_lst)\n",
    "print(gchld.return_even())\n",
    "print(gchld.return_odd())\n",
    "print(gchld.return_reverse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=[{\n",
    "    'id': ['Adam', 'Salman', 'Mike']\n",
    "}, {\n",
    "    'id': ['Ali', 'Bilal', 'Ahmed']\n",
    "}, {\n",
    "    'id': ['Yasir', 'Undertaker', 'Johncena']\n",
    "}, {\n",
    "    'id': ['Sufiyan', 'Adam', 'Ahad']\n",
    "}, {\n",
    "    'id': ['Adam', 'Bruclee', 'BookerT']\n",
    "}])\n",
    "\n",
    "\n",
    "def remove_adam(lst_id):\n",
    "    return [name for name in lst_id if name.lower() != 'adam']\n",
    "\n",
    "\n",
    "df['id'].apply(remove_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50]})\n",
    "df2 = pd.DataFrame({'A': [2, 4, 100], 'D': ['D1', 'D2', 'D3']})\n",
    "df1.merge(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a991ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Barcelona_rent_price.csv')\n",
    "df[df['Average _rent'] == 'average rent (euro/month)'].groupby(\n",
    "    by=['Year', 'Average _rent']).agg({'Price': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Year': [2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002],\n",
    "    'Month': ['Aug', 'Aug', 'Sep', 'Sep', 'Aug', 'Aug', 'Sep', 'Sep'],\n",
    "    'Day': [1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    'Value': [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "})\n",
    "pd.pivot_table(df,\n",
    "               index='Year',\n",
    "               columns='Month',\n",
    "               values='Value',\n",
    "               aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "Label_pos = []\n",
    "\n",
    "tree = ET.parse('./xml_stackoverflow.xml')\n",
    "root = tree.getroot()\n",
    "print(root.text)\n",
    "# for el in root.iter('CompAttrVal'):\n",
    "#     name = el.get('name')\n",
    "#     if name == 'LabelFileName':\n",
    "#         Label_pos.append(el.get('Value'))\n",
    "# print(Label_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbf329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./police.csv')\n",
    "df['stop_date'] = pd.to_datetime(df['stop_date'])\n",
    "df['year'] = df['stop_date'].dt.year\n",
    "last_20_years = df[df['year'] + 3 >= df['year'].max()]\n",
    "last_20_years['year'].unique()\n",
    "# df[df['year'] + 20  >= df['year'].max()]['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73855a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # import numpy not random python module\n",
    "\n",
    "\n",
    "def probs(throws, lis):\n",
    "    dice = list(range(1, 7))\n",
    "    return np.random.choice(dice, throws, p=lis)\n",
    "\n",
    "\n",
    "total = 0\n",
    "throws = 100\n",
    "lis = [0.2, 0.2, 0.2, 0.2, 0.1, 0.1]\n",
    "choices_count = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}\n",
    "while total < 200:\n",
    "    dice = np.random.randint(1, 6)\n",
    "    choices = probs(throws, lis)\n",
    "    if dice in choices:\n",
    "        choices_count[dice] += 1\n",
    "    total += 1\n",
    "\n",
    "print(f'Total Steps: {total}')\n",
    "print(f'Choices count: {choices_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccab8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import *\n",
    "\n",
    "test = \"\"\"\n",
    "pci24 u2480-L0\n",
    "fcs1 g4045-L1\n",
    "pci25 h6045-L0\n",
    "en192 v7024-L3\n",
    "pci26 h6045-L1\n",
    "\"\"\"\n",
    "\n",
    "grammar_pci = Combine(\"pci\" + Word(nums)).setResultsName(\"name\") + Word(\n",
    "    alphanums + \"-\").setResultsName(\"loc\")\n",
    "grammar_non_pci = Suppress(Regex(r\"(?!pci).*\"))\n",
    "\n",
    "grammar = OneOrMore(\n",
    "    Group(grammar_pci).setResultsName(\"pci_slots\", listAllMatches=True)\n",
    "    | grammar_non_pci,\n",
    "    stopOn=StringEnd())\n",
    "\n",
    "data = grammar.parse_string(test, parseAll=True)\n",
    "print(data)\n",
    "data_dict = data.as_dict()\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "xml_file = \"./unbound_prefix.xml\"\n",
    "parser1 = etree.XMLParser(encoding='utf-8', recover=True)\n",
    "xml_tree = etree.parse(xml_file, parser=parser1)\n",
    "root = xml_tree.getroot()\n",
    "for child in root:\n",
    "    print(child.get('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "search_sentence = \"for learning distinctive features among\"\n",
    "raw_sentences = [\n",
    "    \"methods it is possible to among recognize Instagram filters and at-\",  # 01\n",
    "    \"tenuate the sensor pattern noise signal in images. Amerini\",  # 02\n",
    "    \"et al. [10] introduced a CNN for learning distinctive features\",  # 03\n",
    "    \"among social networks. for learning distinctive features among from the histogram of the discrete co-\",  # 04\n",
    "    \"sine transform (DCT) coefficients and the noise residual of\",  # 05\n",
    "    \"the images. Phan et al. [11] proposed a method to track mul-\",  # 06\n",
    "    \"tiple image sharing on social networks by using a CNN for ar-\",  # 07\n",
    "    \"chitecture able to learn\",  # 08\n",
    "    \"et al. [10] introduced a CNN for learning distinctive features among it is possible to among recognize Instagram filters\",  # 09\n",
    "    \"and at- tenuate xx\"\n",
    "]  # 10\n",
    "\n",
    "for sentence in raw_sentences:\n",
    "    result = re.findall(f'\\s+({search_sentence})\\s+', sentence, re.IGNORECASE)\n",
    "    if len(result) > 0:\n",
    "        print(result[0])\n",
    "    else:\n",
    "        print('no matched sentences!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d18e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list1 = ['a', 'b', 'c']\n",
    "list2 = ['d', 'e', 'f']\n",
    "\n",
    "\n",
    "def calculate_test(b, e):\n",
    "    if (not b in list1) or (not e in list2):\n",
    "        #         raise ValueError(\"this should not happen!\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "data = [['a', 'd'], ['b', 'e'], ['c', 'f'], ['g', 'h']]\n",
    "df = pd.DataFrame(data, columns=['first', 'second'])\n",
    "# calculate_test('b','e')  # True\n",
    "try:\n",
    "    df['should_all_be_true'] = df.apply(\n",
    "        lambda row: calculate_test(row['first'], row['second']),\n",
    "        axis=1)  # ValueError raised!\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7de742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "File = pd.read_excel('./data_cleansing.xlsx')\n",
    "File1 = File.copy()\n",
    "print(File1)\n",
    "\n",
    "\n",
    "def replace_func(acct_name, billing_str):\n",
    "    return acct_name.replace(billing_str, '')\n",
    "\n",
    "\n",
    "File1['Account Name'] = File1.apply(\n",
    "    lambda x: replace_func(x['Account Name'], x['Billing Street']), axis=1)\n",
    "File1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "for i in range(8):\n",
    "    for i in range(8):\n",
    "        print(str(randint(0, 1)).ljust(3), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "# findspark.find()\n",
    "\n",
    "# create a Spark Session\n",
    "spark = SparkSession.builder.appName('StackOverflowInitCap').getOrCreate()\n",
    "\n",
    "data = [(1, \"Italy\"), \\\n",
    "        (2, \"italy\"), \\\n",
    "        (3, \"USA\"), \\\n",
    "        (4, \"China\"), \\\n",
    "        (5, \"china\")\n",
    "        ]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"ID\", \"Country\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "\n",
    "def initCap(x):\n",
    "    if x[0].islower():\n",
    "        return x[0].upper() + x[1:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "upperCaseUDF = udf(lambda x: initCap(x), StringType())\n",
    "df.withColumn(\"Country\", upperCaseUDF(df.Country)) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField\n",
    "\n",
    "# create a Spark Session\n",
    "spark = SparkSession.builder.appName('StackOverflowMultiple').getOrCreate()\n",
    "newDF = [\n",
    "    StructField('applianceName', StringType(), True),\n",
    "    StructField('customer', StringType(), True),\n",
    "    StructField('daysAgo', StringType(), True),\n",
    "    StructField('countAnomaliesByDay', IntegerType(), True)\n",
    "]\n",
    "finalStruct = StructType(fields=newDF)\n",
    "df = spark.read.csv('./pyspark_add_multiple_cols.csv',\n",
    "                    schema=finalStruct,\n",
    "                    header=True)\n",
    "df_pivot = df \\\n",
    "    .groupBy('applianceName', 'customer') \\\n",
    "    .pivot('daysAgo') \\\n",
    "    .sum('countAnomaliesByDay')\n",
    "df_pivot.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./stackoverflowacctcard.csv')\n",
    "def collect_card(acct_card):\n",
    "    if len(str(acct_card)) != 9:\n",
    "        return acct_card\n",
    "    else:\n",
    "        return ''\n",
    "def collect_account(acct_card):\n",
    "    if len(str(acct_card)) == 9:\n",
    "        return acct_card\n",
    "    else:\n",
    "        ''\n",
    "df['Card'] = df['Account / Card'].apply(collect_card)\n",
    "df['Account'] = df['Account / Card'].apply(collect_account)\n",
    "df.drop('Account / Card', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce63ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_A = pd.DataFrame([\n",
    "    {'Col 1': '57253,00987(4567)'},\n",
    "    {'Col 1': 'asdf(78985>00987)'}\n",
    "])\n",
    "df_B = pd.DataFrame([\n",
    "    {'Col 1': '57253', 'Col 2': 'TRUE'},\n",
    "    {'Col 1': '78985', 'Col 2': 'NEGATIVE'},\n",
    "    {'Col 1': '00987', 'Col 2': 'LAUGHS'},\n",
    "])\n",
    "def updateVal(v):\n",
    "    for col_1, col_2 in df_B.values:\n",
    "        if col_1 in v:\n",
    "            v = v.replace(col_1, col_2)\n",
    "    return v\n",
    "    \n",
    "df_A['Col 1'] = df_A['Col 1'].apply(updateVal)\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677d244e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is no such driver by url https://chromedriver.storage.googleapis.com/119.0.6045/chromedriver_win32.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19648\\3075348872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# options.add_argument('--disable-blink-features=AutomationControlled')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mservice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChromeService\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://gogohd.pro/download?id=MTkzNTU3&typesub=Gogoanime-SUB&title=Chainsaw+Man+Episode+1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\chrome.py\u001b[0m in \u001b[0;36minstall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m         )\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mdriver_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_driver_binary_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0o755\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\manager.py\u001b[0m in \u001b[0;36m_get_driver_path\u001b[1;34m(self, driver)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please Implement this method\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\download_manager.py\u001b[0m in \u001b[0;36mdownload_file\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"About to download new driver from {url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Driver downloading response is {response.status_code}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\http.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             resp = requests.get(\n\u001b[1;32m---> 33\u001b[1;33m                 url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not reach host. Are you offline?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\http.py\u001b[0m in \u001b[0;36mvalidate_response\u001b[1;34m(resp)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"There is no such driver by url {resp.url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"API Rate limit exceeded. You have to add GH_TOKEN!!!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: There is no such driver by url https://chromedriver.storage.googleapis.com/119.0.6045/chromedriver_win32.zip"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "options = Options()\n",
    "# options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "URL = 'https://gogohd.pro/download?id=MTkzNTU3&typesub=Gogoanime-SUB&title=Chainsaw+Man+Episode+1'\n",
    "driver.get(URL)\n",
    "links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "download_links = []\n",
    "for link in links:\n",
    "    href = link.get_attribute('href')\n",
    "    if href.find('download') != -1:\n",
    "        download_links.append(href)\n",
    "print(download_links)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "shared ={\n",
    "    \"mts\":{\n",
    "        \"account_id\":\"11111\",\n",
    "        \"workbench\":\"aaaaa\",\n",
    "        \"prefix\":\"zzzz\"\n",
    "    },\n",
    "    \"tsf\":{\n",
    "        \"account_id\":\"22222\",\n",
    "        \"workbench\":\"bbbbb\",\n",
    "        \"prefix\":\"yyyy\"\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "role_arn = []\n",
    "for x in shared:\n",
    "   \n",
    "    role = f\"arn:aws:iam::'{shared[x]['account_id']}':role/'{shared[x]['prefix']}'_role\"\n",
    "    if role.find(\"'\") != -1:\n",
    "        role = role.replace(\"'\", \"\")\n",
    "    role_arn.append(role)\n",
    "\n",
    "print(json.dumps(role_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "auxdf =pd.DataFrame({'prod':['look','duck','chik']},index=['prod_team1','prod_team2','prod_team3'])\n",
    "\n",
    "maindf = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [\"aoo\", \"auxdf.loc['prod_team2']\", \"foo\"],\n",
    "        \"col2\": [\"auxdf['prod_team1']\", \"bla\", \"auxdf['prod_team3']\"]\n",
    "    }, index=['mar_team1', 'mar_team2', 'mar_team3']\n",
    ")\n",
    "def replaceFunc(col):\n",
    "    c = re.findall(\"auxdf\\.?\\w*\\['(.*)'\\]\", col)\n",
    "    if len(c) > 0:\n",
    "        col = c[0]\n",
    "        for i, v in zip(auxdf.values, auxdf.index):\n",
    "            if v == col:\n",
    "                col = i[0]\n",
    "    return col\n",
    "maindf['col1'] = maindf['col1'].apply(replaceFunc)\n",
    "maindf['col2'] = maindf['col2'].apply(replaceFunc)\n",
    "maindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4dc91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is no such driver by url https://chromedriver.storage.googleapis.com/119.0.6045/chromedriver_win32.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19648\\2243045104.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# options.add_argument('--disable-blink-features=AutomationControlled')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mservice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChromeService\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.kopykitab.com/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\chrome.py\u001b[0m in \u001b[0;36minstall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m         )\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mdriver_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_driver_binary_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0o755\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\manager.py\u001b[0m in \u001b[0;36m_get_driver_path\u001b[1;34m(self, driver)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please Implement this method\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\download_manager.py\u001b[0m in \u001b[0;36mdownload_file\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"About to download new driver from {url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Driver downloading response is {response.status_code}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\http.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             resp = requests.get(\n\u001b[1;32m---> 33\u001b[1;33m                 url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not reach host. Are you offline?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad ali\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\webdriver_manager\\core\\http.py\u001b[0m in \u001b[0;36mvalidate_response\u001b[1;34m(resp)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"There is no such driver by url {resp.url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"API Rate limit exceeded. You have to add GH_TOKEN!!!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: There is no such driver by url https://chromedriver.storage.googleapis.com/119.0.6045/chromedriver_win32.zip"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "options = Options()\n",
    "# options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "URL = 'https://www.kopykitab.com/'\n",
    "driver.get(URL)\n",
    "links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "for link in links:\n",
    "    href = link.get_attribute('href')\n",
    "    print(f'Link text: {link.text}')\n",
    "    print(f'Link href: {href}')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.otodom.pl/pl/oferty/sprzedaz/mieszkanie/poznan?distanceRadius=0&market=ALL&locations=%5Bcities_6-1%5D&viewType=listing&lang=pl&searchingCriteria=sprzedaz&searchingCriteria=mieszkanie&searchingCriteria=cala-polska\"\n",
    "html_text = requests.get( url ).text\n",
    "soup = BeautifulSoup(html_text, 'lxml') \n",
    "houses = soup.find_all('article', class_ = 'css-n8rq67 es62z2j16')\n",
    "count =1 \n",
    "for i in houses:\n",
    "    print(i.text) \n",
    "    count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "options = Options()\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "URL = 'https://www.otodom.pl/pl/oferty/sprzedaz/mieszkanie/poznan?distanceRadius=0&market=ALL&locations=%5Bcities_6-1%5D&viewType=listing&lang=pl&searchingCriteria=sprzedaz&searchingCriteria=mieszkanie&searchingCriteria=cala-polska'\n",
    "driver.get(URL)\n",
    "houses = driver.find_elements(By.XPATH, \"//article[@class='css-n8rq67 es62z2j16']\")\n",
    "for i in houses:\n",
    "    print(i.text) \n",
    "print(len(houses))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a842fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#Reading the dataset\n",
    "df = pd.read_csv('./stackoverflow_null_values_python.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "df = df[df['year'] == 2020]\n",
    "df_group = df.groupby(['month', 'item_id']).agg(n=('item_id', 'count')).reset_index()\n",
    "pivot_df = pd.pivot_table(df_group, values='n', index='item_id', columns='month', fill_value=0)\n",
    "# feb data\n",
    "feb = pd.DataFrame(pivot_df.loc[:, [2]].to_records()).rename({'2': 'Februrary'}, axis=1)\n",
    "feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_A = my_spark.read.csv('../python3_exercises/stackoverflow_pyspark_missing_df_A', header=True)\n",
    "# df_A.write.saveAsTable(\"df_A\")\n",
    "# df_B = my_spark.read.csv('../python3_exercises/stackoverflow_pyspark_missing_df_B', header=True)\n",
    "# df_B.write.saveAsTable(\"df_B\")\n",
    "# df_B.join(df_A, \n",
    "#           on=[df_B.column1 == df_A.column1, df_B.column2 == df_A.column2, df_B.column3 == df_A.column3],\n",
    "#           how='leftanti'\n",
    "#          ).show()\n",
    "# df_A.join(df_B, \n",
    "#           on=[df_B.column1 == df_A.column1, df_B.column2 == df_A.column2, df_B.column3 == df_A.column3],\n",
    "#           how='leftanti'\n",
    "#          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(a,b,c):\n",
    "    if a>b and a>c:\n",
    "        print(a,\"is largest\")\n",
    "    elif b>a and b>c:\n",
    "        print(b,\"is largest\")\n",
    "    else:\n",
    "        print(c,\"is largest\")\n",
    "x=int(input(\"enter the first number: \"))\n",
    "y=int(input(\"enter the second number: \"))\n",
    "z=int(input(\"enter the third number: \"))\n",
    "maximum(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'x1':[20,25],'y1':[5,8],'x2':[22,27],'y2':[10,2]})\n",
    "df['x_max'] = df[['x1', 'x2']].max(axis=1)\n",
    "df['y_max'] = df[['y1', 'y2']].max(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcab307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example perfectly works for any nested dictionary\n",
    "nested_dict = {\n",
    "    1:{\n",
    "        'name': 'ali',\n",
    "        'gender': 'male',\n",
    "        'friends': {\n",
    "            'name': 'owais'\n",
    "        }\n",
    "    },\n",
    "    2:{\n",
    "        'name': 'eraj',\n",
    "        'gender': 'female',\n",
    "        'friends': {\n",
    "            'name': 'maryam'\n",
    "        }\n",
    "    },\n",
    "    3:{\n",
    "        'name': 'Mojojojo',\n",
    "        'gender': 'male',\n",
    "        'friends': {\n",
    "            'name': 'tanzeel',\n",
    "            'enemies': [\n",
    "                {\n",
    "                    'name': 'Dexter',\n",
    "                    'gender': 'male'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'ali',\n",
    "                    'gender': 'male'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    4:{\n",
    "        'name': 'tanzeel',\n",
    "        'gender': 'male',\n",
    "        'friends': {\n",
    "            'name': 'faisal',\n",
    "            'project_partner': {\n",
    "                'name': 'ali'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    5:{\n",
    "        'name': 'owais',\n",
    "        'gender': 'male',\n",
    "        'friends': {\n",
    "            'name': 'ali'\n",
    "        }\n",
    "    },\n",
    "    6:{\n",
    "        'name': 'maryam',\n",
    "        'gender': 'female',\n",
    "        'friends': {\n",
    "            'name': 'eraj'\n",
    "        },\n",
    "        'fyp_partners': {\n",
    "            'name': 'ali'\n",
    "        }\n",
    "    },\n",
    "}\n",
    "counts_dict = {\n",
    "    'ali': 0, # define your name with declaring 0 count initially\n",
    "    'eraj': 0\n",
    "}\n",
    "# print(hasattr(nested_dict, 'items')) # items is a func of dictionary\n",
    "def search_in_nested(pass_dict):   \n",
    "    if isinstance(pass_dict, dict): # you can also use hasattr(pass_dict, 'items') \n",
    "        for k, v in pass_dict.items():\n",
    "            if (k == 'name' and v == 'ali') or (k == 'name' and v == 'eraj'):\n",
    "                counts_dict[v] += 1 # here increment by one \n",
    "            elif isinstance(v, dict):\n",
    "                search_in_nested(v)\n",
    "            elif isinstance(v, list): # for checking if there's a dict in a list\n",
    "                for lst_item in v:\n",
    "                    search_in_nested(lst_item)\n",
    "search_in_nested(nested_dict)\n",
    "counts_dict # ali exist 5 times and eraj 2 times in this nested dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca699705",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stackoverflow_lines_cut_specific_word.txt') as f:\n",
    "    lines = f.readlines()\n",
    "print(lines)\n",
    "for word in ['ali', 'superb']:\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        if word in line:\n",
    "            lines.remove(line)\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.writelines(lines)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def user():\n",
    "    while True:\n",
    "        print(f\"Blue, Red, Gold, White, Black, Brown\")\n",
    "        user = input(\"Enter a color: \").lower()\n",
    "        if len(re.findall('.?-?[0-9]+', user)) > 0:\n",
    "            print(\"Please enter a valid input, don't pass an number value\")\n",
    "            continue\n",
    "        if user not in ['blue', 'red', 'gold', 'white', 'black', 'brown']:\n",
    "            print('Please only enter')\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return user\n",
    "user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"aaa < bbb < ccc\"\n",
    "output = re.sub(r'(\\w+) < (\\w+) < (\\w+)', r'\\1[\\2] = \\3', str1)\n",
    "print(output)  # aaa[bbb] = ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75338fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game():\n",
    "    print('hello world')\n",
    "    def first_check():\n",
    "        player_sum = sum(player)\n",
    "        dealer_sum = sum(dealer)\n",
    "        if 21 in [player_sum,dealer_sum]:\n",
    "            if 21 in [player_sum] and 21 in [dealer_sum]:\n",
    "                print(\"Both you and the dealer have Blackjack, its a push!!\")\n",
    "        blackjack()\n",
    "\n",
    "is_playing = True\n",
    "while is_playing:\n",
    "    if input(\"Do you want to play again? Y or N \").lower() == 'n':\n",
    "        is_playing = False\n",
    "        print('Game Ends...')\n",
    "        continue\n",
    "    game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491edbd",
   "metadata": {},
   "source": [
    "update 'version=\"2.0.3\"' to 'version=\"1\"' in line that has <coverage<br>\n",
    "rename \"class\" to \"file\"<br>\n",
    "insert new \"</file>\" after every \"\" so that xml syntax is intact.<br>\n",
    "rename \"filename\" to path<br>\n",
    "rename \"line\" to \"lineToCover\"<br>\n",
    "rename \"number\" to \"lineNumber\"<br>\n",
    "delete all lines with \"<source$\" (<source, <sources)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('./stackoverflow_xml_replace.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        if '<coverage' in lines[index]:\n",
    "            lines[index] = lines[index].replace('version=\"2.0.3\"', 'version=\"1\"')\n",
    "        if 'class' in lines[index]:\n",
    "            lines[index] = re.sub(r\"\\bclass\\b\",\"file\",lines[index])\n",
    "        if 'filename' in lines[index]:\n",
    "            lines[index] = re.sub(r\"\\bfilename\\b\",\"path\",lines[index])\n",
    "        if '<line' in lines[index]:\n",
    "            lines[index] = lines[index].replace('line', 'lineToCover')\n",
    "        if 'number' in lines[index]:\n",
    "            lines[index] = re.sub(r\"\\bnumber\\b\",\"lineNumber\",lines[index])\n",
    "        if '<source' in lines[index]:\n",
    "            lines.remove(lines[index])\n",
    "with open('./stackoverflow_xml_replace_output.txt', 'w') as f:\n",
    "    f.writelines(lines)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import *\n",
    "from  pyspark.sql.functions import *\n",
    "data = [{\"REGISTER_DATE\": '', \"FORM_DATE\": '16-12-2022', \"GENDER\": 'Female', \"Truth\": True},\n",
    "{\"REGISTER_DATE\": '13-09-2022', \"FORM_DATE\": '06-12-2022',\"GENDER\": 'Female', \"Truth\":True},\n",
    "{\"REGISTER_DATE\": '', \"FORM_DATE\": '20-12-2022', \"GENDER\": 'Female', \"Truth\": True},\n",
    "{\"REGISTER_DATE\": '', \"FORM_DATE\": '18-12-2022', \"GENDER\": 'Female', \"Truth\": True}]# Define Schema without infering spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "create_df = spark.createDataFrame(data)\n",
    "print('Before converting to date and handling null')\n",
    "create_df.printSchema()\n",
    "create_df.show()\n",
    "create_df = create_df.withColumn('FORM_DATE', to_date(col('FORM_DATE'), 'dd-MM-yyyy'))\n",
    "create_df = create_df.withColumn('REGISTER_DATE', to_date(col('REGISTER_DATE'), 'dd-MM-yyyy'))\n",
    "# Solution 1:\n",
    "# create_df = create_df.withColumn('REGISTER_DATE',when((col('REGISTER_DATE').isNull()) & \n",
    "#     (col('FORM_DATE').isNotNull()) & (col('GENDER')== 'Female'), create_df.FORM_DATE)\n",
    "#     .otherwise(create_df['REGISTER_DATE']))\n",
    "# Solution 2:\n",
    "create_df = create_df.withColumn('REGISTER_DATE', coalesce('REGISTER_DATE', 'FORM_DATE'))\n",
    "# convert back to string \n",
    "create_df = create_df.withColumn('FORM_DATE', col('FORM_DATE').cast('string'))\n",
    "create_df = create_df.withColumn('REGISTER_DATE', col('REGISTER_DATE').cast('string'))\n",
    "print('After converting to date and handling null')\n",
    "create_df.printSchema()\n",
    "create_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3028e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_2d(num_1, num_2):\n",
    "    arr = np.arange(num_1, num_2 + 1)\n",
    "    return (np.reshape(arr, (2, 3)) ** 2) + 5\n",
    "# convert_2d(int(input('Enter no 1: ')), int(input('Enter no 2: ')))\n",
    "convert_2d(2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd785bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import clear\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/Test/Downloads/chromedriver_win32/chromedriver.exe\",options=chrome_options)#VariablesID1 = \"slice0Flight1MainCabin\"\n",
    "\n",
    "NAME = \"segments[0].orgin\"\n",
    "\n",
    "NAME1 = \"segments[0].destination\"\n",
    "\n",
    "NAME2 = \"segments[0].travelDate\"\n",
    "\n",
    "NAME3 = \"segments[1].travelDate\"\n",
    "\n",
    "NAME4 = \"closeBannerButton\"\n",
    "\n",
    "XPATH = \"//*[@id='flightSearchSubmitBtn']\"\n",
    "\n",
    "XPATH2 = \"//*[@id='slice0Flight1MainCabin']\"\n",
    "\n",
    "LINK_TEXT = \"https://www.aa.com/booking/find-flights\"\n",
    "\n",
    "driver.get(LINK_TEXT)\n",
    "\n",
    "print(driver.title)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "button = driver.find_element(By.NAME, NAME4)\n",
    "button.click()\n",
    "\n",
    "search = driver.find_element(By.NAME, NAME)\n",
    "search.send_keys(\"PHX\")\n",
    "\n",
    "search = driver.find_element(By.NAME, NAME1)\n",
    "\n",
    "search.send_keys(\"LHR\")\n",
    "\n",
    "search = driver.find_element(By.NAME, NAME2)\n",
    "\n",
    "search.send_keys(\"09/20/23\")\n",
    "\n",
    "time.sleep(5)\n",
    "search = driver.find_element(By.NAME, NAME3)\n",
    "\n",
    "search.send_keys(\"09/27/23\")\n",
    "\n",
    "time.sleep(5)\n",
    "button = driver.find_element(By.XPATH, XPATH)\n",
    "\n",
    "button.click()\n",
    "\n",
    "#Sleep timertime.sleep(45)\n",
    "\n",
    "button = driver.find_element(By.XPATH, XPATH)\n",
    "\n",
    "button.click()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [3, 1]\n",
    "benchmark = 2\n",
    "if any(ele > benchmark for ele in mylist):\n",
    "    print('True')\n",
    "else:\n",
    "    print('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825194ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=[{'result': 'M'}, {'result':'B'}, {'result':'B'}, {'result':'M'}])\n",
    "# Sol 1\n",
    "def changeValue(r):\n",
    "    if r == 'M':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df.apply(lambda x: changeValue(x['result']), axis=1)\n",
    "# Sol 2\n",
    "# df['result'].map({'M': 0, 'B': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81884ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.DataFrame(\n",
    "    data=\n",
    "    [\n",
    "        {'emp_length': '10+years'},\n",
    "        {'emp_length': '3 years'},\n",
    "        {'emp_length': '<1 year'}\n",
    "    ]\n",
    "                 )\n",
    "df['emp_length'] = df['emp_length'].str.extract(r'(\\d+)')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "wb = load_workbook(filename = './formula_contains_raw.xlsx', ).active\n",
    "print(wb.values)\n",
    "# sheet_names = wb.get_sheet_names()[0]\n",
    "# sheet_ranges = wb[name]\n",
    "df = pd.DataFrame(list(wb.values)[1:], columns=list(wb.values)[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dirty_data.csv')\n",
    "# df.to_parquet('dirty_data.parquet') # install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 + i for i in range(1, 5)].append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def check_v_c(word):\n",
    "    result = []\n",
    "    for i in word:\n",
    "        if i.lower() in \"aeious\":\n",
    "            result.append(f'{i} is a vowel')\n",
    "        elif i in string.punctuation:\n",
    "            result.append(f'{i} is a punchuation')\n",
    "        else:\n",
    "            result.append(f'{i} is a consonant')\n",
    "    return result\n",
    "print('\\n'.join(check_v_c(\"Mon.ey\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e589ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "phrase = \"www.usatoday.com/story/travel/airline-news/2022/10/04/airplane-behaviors-reclining-seats-overhead-bins-shoes/8129315001/\"\n",
    "\n",
    "text = '/story/'       ## uses BOTH \"/\"\n",
    "text = text.replace('/', '')\n",
    "re.findall(f'\\/{text}\\/', phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "res = requests.get('https://ll.thespacedevs.com/2.0.0/launch/upcoming')\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a586111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "groceries = {\n",
    "    'grocery': [\n",
    "        \"Tesco's wafers\", \"Asda's shortbread\", \"Aldi's lemon tea\",\n",
    "        \"Sainsbury's croissant\", \"Morrison's doughnut\",\n",
    "        \"Amazon fresh's peppermint tea\", \"Bar becan's pizza\",\n",
    "        \"Pound savers' shower gel\"\n",
    "    ],\n",
    "    'category': [\n",
    "        'biscuit', 'biscuit', 'tea', 'bakery', 'bakery', 'tea', 'bakery',\n",
    "        'hygiene'\n",
    "    ],\n",
    "    'price': [0.99, 1.24, 1.89, 0.75, 0.50, 2.5, 4.99, 2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(groceries)\n",
    "# split it with \"'\" comma and then start it with from 1 index of a string \n",
    "# if multiple conditions for grocery string then \n",
    "\n",
    "# def grocery_chng(x):\n",
    "#     # specify multiple conditions to replace a string\n",
    "#     return x\n",
    "# df['grocery'] = df['grocery'].apply(grocery_chng)\n",
    "\n",
    "df['grocery'] = df['grocery'].apply(lambda x: x.split(\"'\")[1][1:].title())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {\n",
    "  \"foo\": [\n",
    "    50,\n",
    "    100\n",
    "  ],\n",
    "  \"bar\": [\n",
    "    5,\n",
    "    10\n",
    "  ],\n",
    "  \"noto\": [\n",
    "      11,\n",
    "      30\n",
    "  ]\n",
    "}\n",
    "df_1 = pd.DataFrame(\n",
    "    {\n",
    "        \"keys\": d.keys(),\n",
    "        \"vals\": d.values()\n",
    "    }\n",
    ")\n",
    "df_1\n",
    "df_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"item\": [\"foo\", \"bar\", \"noto\"],\n",
    "        \"price\": [65, 7, 33]\n",
    "    }\n",
    ")\n",
    "main_df = df_1.merge(df_2, left_on='keys', right_on=\"item\")\n",
    "def check_price(x):\n",
    "    return x['price'] >= x['vals'][0] and x['price'] <= x['vals'][1]\n",
    "main_df[main_df.apply(lambda x: check_price(x), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Date_Time': [\n",
    "        '2017-08-08 23:55:01', '2017-08-08 23:50:01', '2017-08-08 06:45:01',\n",
    "        '2017-08-08 05:40:01', '2017-08-08 00:35:01',\n",
    "        '2017-07-26 00:23:57', '2017-07-26 00:18:57', '2017-07-26 07:13:57',\n",
    "        '2017-07-26 00:08:57', '2017-07-26 07:03:57'\n",
    "    ],\n",
    "    'Level': [239.0, 242.0, 246.0, 250.0, 254.0, 72.0, 67.0, 64.0, 64.0, 65.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Date_Time', 'Level'])\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'])\n",
    "df = df.set_index('Date_Time')\n",
    "df['period'] = pd.cut(\n",
    "    df.index.hour,\n",
    "    bins=[0, 6, 23.99],\n",
    "    labels=['00:00:00 - 06:00:00', '06:00:01 - 23:59:99'],\n",
    "    include_lowest=True\n",
    ")\n",
    "df.groupby([df.index.date, 'period'])['Level'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f908ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=8\n",
    "def example(a):\n",
    "    global q\n",
    "    q=q+2\n",
    "    print(q)\n",
    "    print(a)\n",
    "example(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "excel = openpyxl.Workbook()\n",
    "sheet = excel.active\n",
    "sheet.title = \"Open food facts\"\n",
    "\n",
    "# sheet.append(['Name', 'Barcode', 'Common Name', 'Quantity', 'Packaging', 'Categories', 'Labels, certifications, awards',\n",
    "#               'Stores', 'Countries where sold', 'Nutri_Score_Description', 'NOVA_Description', 'ECO_Score_Description',\n",
    "#               'ingredient', 'allergen', 'fat_in_quantity', 'saturated_fat_in_quantity', 'sugar_in_quantity', 'salt_in_quantity'])\n",
    "\n",
    "baseurl = \"https://world.openfoodfacts.org/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "productlinks = []\n",
    "\n",
    "# it means 2,3 --> page 4 is excluded\n",
    "for x in range(2, 4):\n",
    "    r = requests.get(f'https://world.openfoodfacts.org/{x}')\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    productlist = soup.find_all('a')\n",
    "    for i in productlist:\n",
    "        a = i.get('href')\n",
    "        if a and '/product/' in a:\n",
    "            productlinks.append(a)\n",
    "# print(productlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d34e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data = []\n",
    "for link in productlinks:\n",
    "    r = requests.get(f'https://world.openfoodfacts.org{link}', headers=headers)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "    try:\n",
    "        item_name = soup.find('h2', class_='title-1').text.strip().replace('\\n', ' ')\n",
    "    except:\n",
    "        item_name = \"No names\"\n",
    "\n",
    "    try:\n",
    "        common_name = soup.find('span', class_='field_value').text.strip()\n",
    "    except:\n",
    "        common_name = \"No common names\"\n",
    "\n",
    "    try:\n",
    "        barcode = soup.find('span', id='barcode').text.strip()\n",
    "    except:\n",
    "        barcode = \"No barcodes\"\n",
    "\n",
    "    try:\n",
    "        qty = soup.find('span', id='field_quantity_value').text.strip()\n",
    "    except:\n",
    "        qty = \"No Quantitys\"\n",
    "\n",
    "    try:\n",
    "        list_packaging = soup.find_all('span', id='field_packaging_value')\n",
    "        packaging_list = [package.text.strip() for package in list_packaging]\n",
    "        packaging = ', '.join(packaging_list) if packaging_list else 'No Packages'\n",
    "    except:\n",
    "        packaging = 'No Packages'\n",
    "\n",
    "    try:\n",
    "        list_categories = soup.find_all('span', id='field_categories_value')\n",
    "        category_list = [category.text.strip() for category in list_categories]\n",
    "        categories = ', '.join(category_list) if category_list else 'No Categories'\n",
    "    except:\n",
    "        categories = 'No Categories'\n",
    "\n",
    "    try:\n",
    "        list_labels = soup.find_all('span', id='field_labels_value')\n",
    "        label_list = [label.text.strip() for label in list_labels]\n",
    "        labels = ', '.join(label_list) if label_list else 'No Labels, certifications, awards'\n",
    "    except:\n",
    "        labels = 'No Labels, certifications, awards'\n",
    "\n",
    "    try:\n",
    "        list_stores = soup.find_all('span', id='field_stores_value')\n",
    "        store_list = [store.text.strip() for store in list_stores]\n",
    "        stores = ', '.join(store_list) if store_list else 'No Stores'\n",
    "    except:\n",
    "        stores = 'No Stores'\n",
    "\n",
    "    try:\n",
    "        list_countries = soup.find_all('span', id='field_countries_value')\n",
    "        country_list = [country.text.strip() for country in list_countries]\n",
    "        countries = ', '.join(country_list) if country_list else 'No Countries'\n",
    "    except:\n",
    "        countries = 'No Countries'\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nutriscore_content\")\n",
    "        Nutri_Score_Description = a_element.find('h4').text.strip()\n",
    "    except:\n",
    "        Nutri_Score_Description = \"NO Nutri Score Description Available\"\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nova_content\")\n",
    "        NOVA_Description = a_element.find('h4').text.strip()\n",
    "    except:\n",
    "        NOVA_Description = \"NO NOVA Description Available\"\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_ecoscore_content\")\n",
    "        ECO_Score_Description = a_element.find('h4').text.strip()\n",
    "    except:\n",
    "        ECO_Score_Description = \"NO ECO Score Description Available\"\n",
    "\n",
    "    try:\n",
    "        ingredient = soup.find('div', id='panel_ingredients_content').find('div', class_='panel_text').get_text(strip=True)\n",
    "    except:\n",
    "        ingredient = 'No Ingredients'\n",
    "\n",
    "    try:\n",
    "        allergen = soup.find('div', id='panel_ingredients_content').find('strong', text='Allergens:').next_sibling.strip()\n",
    "    except:\n",
    "        allergen = 'No Allergen'\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nutrient_level_fat_content\")\n",
    "        fat_in_quantity = a_element.find('h4', class_='evaluation__title').text.strip()\n",
    "    except:\n",
    "        fat_in_quantity = \"No Fat In Quantitys\"\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nutrient_level_saturated-fat_content\")\n",
    "        saturated_fat_in_quantity = a_element.find('h4', class_='evaluation__title').text.strip()\n",
    "    except:\n",
    "        saturated_fat_in_quantity = \"No Saturated Fat In Quantitys\"\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nutrient_level_sugars_content\")\n",
    "        sugar_in_quantity = a_element.find('h4', class_='evaluation__title').text.strip()\n",
    "    except:\n",
    "        sugar_in_quantity = \"No Sugar In Quantitys\"\n",
    "\n",
    "    try:\n",
    "        a_element = soup.find('a', href=\"#panel_nutrient_level_salt_content\")\n",
    "        salt_in_quantity = a_element.find('h4', class_='evaluation__title').text.strip()\n",
    "    except:\n",
    "        salt_in_quantity = \"No Salt In Quantitys\"\n",
    "\n",
    "    food = {\n",
    "        'Name': item_name,\n",
    "        'Barcode': barcode,\n",
    "        'Common Name': common_name,\n",
    "        'Quantity': qty,\n",
    "        'Packaging': packaging,\n",
    "        'Categories': categories,\n",
    "        'Labels, certifications, awards':labels,\n",
    "        'Stores': stores,\n",
    "        'Countries where sold': countries,\n",
    "        'Nutri_Score_Description': Nutri_Score_Description,\n",
    "        'NOVA_Description': NOVA_Description,\n",
    "        'ECO_Score_Description':ECO_Score_Description,\n",
    "        'ingredient': ingredient,\n",
    "        'allergen': allergen,\n",
    "        'fat_in_quantity': fat_in_quantity,\n",
    "        'saturated_fat_in_quantity': saturated_fat_in_quantity,\n",
    "        'sugar_in_quantity': sugar_in_quantity,\n",
    "        'salt_in_quantity':salt_in_quantity\n",
    "    }\n",
    "    food_data.append(food)\n",
    "sheet.append(food_data)\n",
    "excel.save('openfoodfact.xlsx')\n",
    "food_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession object\n",
    "spark = SparkSession.builder.appName(\"CreateDataFrame\").getOrCreate()\n",
    "\n",
    "# Use the SparkSession object to create a DataFrame\n",
    "df_day_of_week = spark.createDataFrame([(0, \"Sunday\"), (1, \"Monday\"),\n",
    "                                        (2, \"Tuesday\"), (3, \"Wednesday\"),\n",
    "                                        (4, \"Thursday\"), (5, \"Friday\"),\n",
    "                                        (6, \"Saturday\")],\n",
    "                                       [\"day_of_week_num\", \"day_of_week\"])\n",
    "# Show the DataFrame\n",
    "df_day_of_week.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import StructType, StringType, DateType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"loan_filter\").getOrCreate()\n",
    "schema = StructType() \\\n",
    "      .add(\"Name\",StringType(),True) \\\n",
    "      .add(\"ID\",StringType(),True) \\\n",
    "      .add(\"ContractDate\",DateType(),True) \\\n",
    "      .add(\"LoanSum\",IntegerType(),True) \\\n",
    "      .add(\"ClosingDate\",DateType(),True)\n",
    "df_or = spark.read.csv('./pyspark_loan.csv', header=True, schema=schema)\n",
    "# two loans should be granted at the same day;\n",
    "# ============================================================================\n",
    "df = df_or.groupBy('Name', 'ID',\n",
    "                   'ContractDate').count().filter(f.col('count') == 2)\n",
    "d_2 = df_or.join(df,\n",
    "                 on=[\n",
    "                     df_or['Name'] == df['Name'], df_or['ID'] == df['ID'],\n",
    "                     df_or['ContractDate'] == df['ContractDate']\n",
    "                 ],\n",
    "                 how='inner').select(df_or['Name'], df_or['ID'],\n",
    "                                     df_or['ContractDate'], df_or['LoanSum'],\n",
    "                                     df_or['ClosingDate'])\n",
    "# ============================================================================\n",
    "# The difference between firstClosingDate and ContractDate should be less than 5\n",
    "# first gets the first value of closingDate for a ID\n",
    "w1 = Window().partitionBy('ID').orderBy('ClosingDate')\n",
    "d_2 = d_2.withColumn('FirstClosingDate',\n",
    "                     f.first('ClosingDate',\n",
    "                             True).over(w1)).orderBy('Name', 'ID',\n",
    "                                                     'ContractDate')\n",
    "d_2 = d_2.filter(\n",
    "    f.datediff(d_2['ContractDate'], d_2['FirstClosingDate']) <= 5).select(\n",
    "        'Name', 'ID', 'ContractDate', 'LoanSum', 'ClosingDate')\n",
    "d_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060151c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 1]\n",
       "Name: A, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "lst = [0, 1, 2]\n",
    "dg = pd.DataFrame({'A': pd.cut(range(1, 2, 3), bins=[0, 1, 2])})\n",
    "# replace ( with [ and convert it into string\n",
    "dg['A'] = dg['A'].astype(str).str.replace('(', '[', regex=True)\n",
    "file_name = 'myfile.feather'\n",
    "# dg.to_feather(file_name)\n",
    "dg.to_feather(file_name)\n",
    "# dg.to_pickle(file_name)\n",
    "# dg = pd.read_feather(file_name)\n",
    "dg = pd.read_feather(file_name)\n",
    "# dg = pd.read_pickle(file_name)\n",
    "dg['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1842d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 1]\n",
       "Name: A, dtype: category\n",
       "Categories (1, object): ['[0, 1]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg['A'].apply(lambda x: x.replace(\"'\", \"\")).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61064691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=ES&q=inmobiliaria&search_type=keyword_unordered&media_type=all\"\n",
    "html_text = requests.get( url ).text\n",
    "soup = BeautifulSoup(html_text, 'html.parser') \n",
    "soup.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0b1171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'didnt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e2bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
